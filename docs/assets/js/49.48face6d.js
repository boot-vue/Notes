(window.webpackJsonp=window.webpackJsonp||[]).push([[49],{421:function(t,a,e){"use strict";e.r(a);var r=e(12),s=Object(r.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"kafka-💥"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#kafka-💥"}},[t._v("#")]),t._v(" Kafka 💥")]),t._v(" "),e("blockquote",[e("p",[t._v("基于发布/订阅模式")])]),t._v(" "),e("p",[t._v("旧版本 Zookeeper 有存消息消费位置 新版本直接存储到 kafaka 集群中\n消息保存根据 Topic 归类, producer 与 consumer, 集群中每个 kafka 实例称为 broker, 整个集群与 consumer 依赖 zookeeper, kafka 只支持 consumer poll 轮询获取消息.")]),t._v(" "),e("h2",{attrs:{id:"topic"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#topic"}},[t._v("#")]),t._v(" Topic")]),t._v(" "),e("p",[t._v("分区 数据存储, topic 下包含 "),e("code",[t._v("leader")]),t._v(" 与 "),e("code",[t._v("follower")]),t._v(", 一个 topic 实际就是一个文件目录")]),t._v(" "),e("h2",{attrs:{id:"consumer"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#consumer"}},[t._v("#")]),t._v(" Consumer")]),t._v(" "),e("p",[t._v("同一个组下的 consumer 不能消费同一个分区的数据")]),t._v(" "),e("h2",{attrs:{id:"配置"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#配置"}},[t._v("#")]),t._v(" 配置")]),t._v(" "),e("p",[t._v("broker 集群:")]),t._v(" "),e("p",[t._v("server.properties")]),t._v(" "),e("div",{staticClass:"language-properties extra-class"},[e("pre",{pre:!0,attrs:{class:"language-properties"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#设置唯一的id")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("broker.id")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("0")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#允许删除")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("delete.topic.enable")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("true")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#logs目录  不只日志  数据也存在这里")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("log.dirs")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("....")]),t._v("\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("#zookeeper")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("zookeeper.connect")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("=")]),e("span",{pre:!0,attrs:{class:"token attr-value"}},[t._v("xxxx:2181,xxxx:2181")]),t._v("\n")])])]),e("h2",{attrs:{id:"数据可靠性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#数据可靠性"}},[t._v("#")]),t._v(" 数据可靠性")]),t._v(" "),e("blockquote",[e("p",[t._v("生产者发送消息, 全部分区都要同步成功 返回成功 ACK, 生产者继续发")])]),t._v(" "),e("blockquote",[e("p",[t._v("leader---\x3efollower 同步节点慢的或者挂了的剔出同步")])]),t._v(" "),e("blockquote",[e("p",[t._v("某些不重要的数据, 不需要完全同步成功")])]),t._v(" "),e("h3",{attrs:{id:"一致性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#一致性"}},[t._v("#")]),t._v(" 一致性")]),t._v(" "),e("p",[t._v("数据不一致, 消费者可见 offset: 所有节点都有的数据最小的 log end offset\n重新选举 leader 时, 不同副本不一致的数据(>log end offset)的数据丢弃")]),t._v(" "),e("h2",{attrs:{id:"命令"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#命令"}},[t._v("#")]),t._v(" 命令")]),t._v(" "),e("ol",[e("li",[t._v("插入 topic :")])]),t._v(" "),e("blockquote",[e("p",[t._v("bin/kafka-topics.sh --create --zookeeper xxx:2181 --partitions 2 --replication-factor 3 --topic test")])]),t._v(" "),e("p",[t._v("2 个分区 3 个副本, 每个分区实际创建了一个文件目录. 副本数不能大于 zookeeper 集群上注册的 broker 数量")]),t._v(" "),e("ol",{attrs:{start:"2"}},[e("li",[t._v("查询 topic:")])]),t._v(" "),e("blockquote",[e("p",[t._v("bin/kafka-topics.sh --list --zookeeper xxxx:2181")])]),t._v(" "),e("ol",{attrs:{start:"3"}},[e("li",[t._v("producer 发送消息:")])]),t._v(" "),e("blockquote",[e("p",[t._v("bin/kafka-console-producer.sh --broker-list xxxx:9092 --topic test")])]),t._v(" "),e("ol",{attrs:{start:"4"}},[e("li",[t._v("consumer 消费消息:")])]),t._v(" "),e("blockquote",[e("p",[t._v("bin/kafka-console-consumer.sh --zookeeper xxx:2181 --topic test [--from-beginning] (新版本消费端消息的 offset 直接维护在 broker 中, 不走 zookeeper)")])]),t._v(" "),e("blockquote",[e("p",[t._v("bin/kafka-console-consumer.sh --bootstrap-server xxx:9092 --topic test [--from-beginning]")])]),t._v(" "),e("h2",{attrs:{id:"ack"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#ack"}},[t._v("#")]),t._v(" ACK")]),t._v(" "),e("ol",[e("li",[t._v("0: 不停的发,无需 ack")]),t._v(" "),e("li",[t._v("1: leader 确认以后继续发")]),t._v(" "),e("li",[t._v("all(-1): leader 与所有的 consumer 应答确认后继续发")])]),t._v(" "),e("blockquote",[e("p",[t._v("要么重复 要么丢数据")])]),t._v(" "),e("h3",{attrs:{id:"幂等性"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#幂等性"}},[t._v("#")]),t._v(" 幂等性")]),t._v(" "),e("p",[t._v("去重 "),e("code",[t._v("enbale.idompotence=true")]),t._v(" ack 默认为 all(-1)")]),t._v(" "),e("h2",{attrs:{id:"java-api"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#java-api"}},[t._v("#")]),t._v(" Java Api")]),t._v(" "),e("ol",[e("li",[t._v("KafkaProducer, KafkaConsumer")]),t._v(" "),e("li",[t._v("SimpleConsumer---\x3e遍历, 获取某个 topic,某个分区的 leader--\x3e通过 leader host ,构造 SimpleConsumer 获取数据")])]),t._v(" "),e("h2",{attrs:{id:"stream-流式处理"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#stream-流式处理"}},[t._v("#")]),t._v(" Stream 流式处理")]),t._v(" "),e("p",[t._v("弱鸡")])])}),[],!1,null,null,null);a.default=s.exports}}]);